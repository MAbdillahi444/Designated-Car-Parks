# Testing

## Test Plan
Software engineers differentiate between software faults and software failures in their professional practice. The software fails to execute its intended user functions. Programming errors which could produce system failures are known as faults yet they lack proven instances of failure occurrence. The semantic correctness error in the design of computer programs constitutes a fault in programming. A fault develops into a failure when the computation conditions are fulfilled and the faulty computer program section runs on the CPU. A programming fault has the potential to evolve into software failure if software developers port applications to new compilers or translate them between hardware systems or create program extensions.

Testing goals work to build organizational confidence in software quality which leads to a satisfactory defect percentage. Software defect rates that organizations accept vary based on the characteristics of specific software systems. Software testing faces the challenge of having large numbers of product defects alongside even higher possible product configuration levels. Uncommon defects are hard to detect during the testing period. Software testing duration must surpass the anticipated system operating duration because it serves as a baseline for reliability assurance. A project seeking to develop long-lived dependable software faces commercial limitations when testing beyond a standard timeframe unless testing spans a brief amount of time. System verification usually needs a few working days or one week using standard operational start and conclusion protocols yet demands simulations for any lengthier durations.

Testing a software product commonly happens through independent tester groups who operate following development until product shipment occurs to customers. Such practices enable the testing phase to function as a delay compensation method which reduces testing duration. The practice begins testing software at project startup with testing reflecting an unbroken process until project completion.




Software Testing Standard

1. It is impossible to test a program completely.
2. Software testing is risk-based exercise.
3. Testing cannot show that bugs don't exist.
4. The more bugs you find, the more bugs there are.
5. Not all the bugs you find will be fixed.
6. Product specifications are never final.


Verification and Validation

Software testing operates together with verification and validation (V&V) procedures. The act of testing items including software for their adherence to their specified standards is known as verification. Among verification methods used for testing stands software testing along with reviews inspections and walkthroughs. The validation method checks if the user desired elements align with the original specification.

The product needs verification testing to show whether the program meets its specification. Our objective is to verify whether we assembled the correct software system according to customer requirements. Does what the customer need to have? 


â€ƒ


TODO: Describe any manual and automated (unit) tests. Uniquely identify each test case. Include prerequisites and test data.

Test Runs
TODO: For each test described above, indicate the current status. 
Create a requirements traceability matrix to validate the completeness of the product.

| Use-Case ID | Requirement ID | Test Case | Status |
| ----------- | -------------- | --------- | ------ |
| ----------- | -------------- | --------- | ------ |
| ----------- | -------------- | --------- | ------ |
| ----------- | -------------- | --------- | ------ |


TODO: Add rows for each test, current status is eg. pass/fail
